[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Operating Systems and Networs SoSe 25 Solutions",
    "section": "",
    "text": "Preface",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "sh01/01.html",
    "href": "sh01/01.html",
    "title": "1  Blatt 01",
    "section": "",
    "text": "Aufgabe 1\nLearning how to Learn:\nJohn Cleese:",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Blatt 01</span>"
    ]
  },
  {
    "objectID": "sh01/01.html#aufgabe-1",
    "href": "sh01/01.html#aufgabe-1",
    "title": "1  Blatt 01",
    "section": "",
    "text": "Zwei Denkmodi aus „Learning How to Learn“\n\nFokussierter Modus: Zielgerichtetes, konzentriertes Denken. Gut für bekannte Aufgaben und Übung.\nDiffuser Modus: Entspanntes, offenes Denken. Hilft bei neuen Ideen und kreativen Verknüpfungen.\n\nAufgaben und passende Denkmodi\n\nFokussierter Modus\nWarum: Erfordert Konzentration und gezieltes Einprägen.\nZuerst diffuser, dann fokussierter Modus\nWarum: Erst Überblick und Verständnis aufbauen, dann vertiefen.\n\nFokussierter Modus\nWarum: Klare, schrittweise Übung – ideal für fokussiertes Denken.\nBeide Modi\nWarum: Fokussiert für Details & Übungen, diffus für Überblick & Vernetzung.\n\n\n\n\nZwei Denkmodi:\n\nOffener Modus: Locker, spielerisch, kreativ.\nBeispiel: Ideen für eine Geschichte sammeln.\nWarum: Offenheit fördert neue Einfälle.\n\nGeschlossener Modus: Zielgerichtet, angespannt, entscheidungsfreudig.\nBeispiel: Bericht überarbeiten und fertigstellen.\nWarum: Präzises Arbeiten und klare Entscheidungen nötig.\n\n\nVergleich mit „Learning How to Learn“\n\nOffen \\(\\Leftrightarrow\\) Diffus: Für Kreativität und Überblick.\n\nGeschlossen \\(\\Leftrightarrow\\) Fokussiert: Für Detailarbeit und Umsetzung.\n\nAlexander Fleming:\n\nModus: Offen\nWarum: Fleming entdeckte Penicillin zufällig, weil er offen und entspannt war – neugierig statt zielgerichtet. Im geschlossenen Modus hätte er die verschimmelte Petrischale wohl einfach weggeschmissen – zu fokussiert für zufällige Entdeckungen.\n\nAlfred Hitchcock:\n\nModus: Offen\n\nWie: Er erzählte lustige Anekdoten, um das Team zum Lachen zu bringen – so schuf er eine entspannte Atmosphäre, die kreatives Denken förderte.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Blatt 01</span>"
    ]
  },
  {
    "objectID": "sh01/01.html#aufgabe-2",
    "href": "sh01/01.html#aufgabe-2",
    "title": "1  Blatt 01",
    "section": "Aufgabe 2",
    "text": "Aufgabe 2\n\n\nx64: 16 64 Bit GPRs1 \\(\\Rightarrow\\) 16 x 64 b = 16 x 8 B = \\(2^7\\) B.\nAVX2: 16 256 Bit GPRs2 \\(\\Rightarrow\\) 16 x 256 b = 16 x 32 B = \\(2^9\\) B\n\n\nx64: \\(\\frac{2^7}{2^{30}} = \\frac{1}{2^{23}}\\)\nAVX2: \\(\\frac{2^9}{2^{30}} = \\frac{1}{2^{21}}\\)\n\nallgemein gilt: \\(10^3 \\approx 2^{10}\\), und \\(\\frac{2^x}{2^y} = \\frac{1}{2^{y-x}}\\)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Blatt 01</span>"
    ]
  },
  {
    "objectID": "sh01/01.html#aufgabe-3",
    "href": "sh01/01.html#aufgabe-3",
    "title": "1  Blatt 01",
    "section": "Aufgabe 3",
    "text": "Aufgabe 3\n\nDer Zugriff scheitert, weil der Arbeitsspeicher durch die Memory Protection (z. B. Paging mit Zugriffsrechten) vom Betriebssystem isoliert wird. Nur der Kernel darf die Speicherbereiche aller Prozesse sehen und verwalten.\nEin Prozess kann trotzdem auf Ressourcen anderer Prozesse zugreifen über kontrollierte Schnittstellen wie IPC (Inter-Process Communication), Dateisysteme, Sockets oder Shared Memory, die vom Betriebssystem verwaltet und überwacht werden.\nWelche Risiken entstehen bei höchstem Privileg für alle Prozesse?\n\nSicherheitslücken: Jeder Prozess könnte beliebige Speicherbereiche lesen/schreiben.\n\nStabilitätsprobleme: Fehlerhafte Prozesse könnten das System zum Absturz bringen.\n\nKeine Isolation: Malware hätte vollen Systemzugriff, keine Schutzmechanismen.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Blatt 01</span>"
    ]
  },
  {
    "objectID": "sh01/01.html#aufgabe-4",
    "href": "sh01/01.html#aufgabe-4",
    "title": "1  Blatt 01",
    "section": "Aufgabe 4",
    "text": "Aufgabe 4\nKernel-Code benötigt einen sicheren, kontrollierten Speicherbereich (seinen eigenen Stack), um zu vermeiden:\n\nBeschädigung durch Benutzerprozesse\nAbstürze oder Rechteausweitung (Privilege Escalation)\n\nDaher hat jeder Prozess:\n\nEinen User-Mode-Stack (wird bei normaler Ausführung verwendet)\nEinen Kernel-Mode-Stack (wird bei System Calls und Interrupts verwendet)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Blatt 01</span>"
    ]
  },
  {
    "objectID": "sh01/01.html#aufgabe-5",
    "href": "sh01/01.html#aufgabe-5",
    "title": "1  Blatt 01",
    "section": "Aufgabe 5",
    "text": "Aufgabe 5\nEntfernte Systemaufrufe\n\n\n\n\n\n\n\nSystemaufruf\nGrund für Entfernung\n\n\n\n\ncreat\nEntspricht vollständig open(path, O_CREAT | O_WRONLY | O_TRUNC, mode).\n\n\ndup\nEntspricht vollständig fcntl(fd, F_DUPFD, 0).\n\n\n\nAlle übrigen Systemaufrufe bieten essenzielle Funktionen, die nicht exakt durch andere ersetzt werden können.\nSie decken ab:\n\nDatei- und Verzeichnisoperationen (open, read, write, unlink, mkdir, etc.)\nProzessmanagement (fork, exec, wait, exit, etc.)\nMetadatenverwaltung (chmod, chown, utime, etc.)\nKommunikation und Steuerung (pipe, kill, ioctl, etc.)\nZeit- und Systemabfragen (time, times, stat, etc.)\n\nOhne sie wären bestimmte Kernfunktionen unmöglich.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Blatt 01</span>"
    ]
  },
  {
    "objectID": "sh01/01.html#aufgabe-6",
    "href": "sh01/01.html#aufgabe-6",
    "title": "1  Blatt 01",
    "section": "Aufgabe 6",
    "text": "Aufgabe 6\nscript.sh auch im Zip:\ncd $1\nwhile :\ndo\n    echo \"5 biggest files in $1:\"\n    ls -S | head -5\n    echo \"5 last modified files starting with '$2' in $1:\"\n    ls -t | grep ^$2 | head -5\n    sleep 5\ndone",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Blatt 01</span>"
    ]
  },
  {
    "objectID": "sh01/01.html#aufgabe-7",
    "href": "sh01/01.html#aufgabe-7",
    "title": "1  Blatt 01",
    "section": "Aufgabe 7",
    "text": "Aufgabe 7\nVorteile:\n\nKomplexitätsreduktion: Abstraktionen verbergen technische Details und erleichtern das Entwickeln und Verstehen von Systemen.\n\nWiederverwendbarkeit: Einmal geschaffene Abstraktionen (z.B. Dateisystem, Prozesse) können flexibel in verschiedenen Programmen genutzt werden.\n\nNachteile:\n\nLeistungsaufwand: Abstraktionsschichten können zusätzliche Rechenzeit und Speicherverbrauch verursachen.\n\nFehlerverdeckung: Probleme in tieferen Schichten bleiben oft verborgen und erschweren Fehlersuche und Optimierung.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Blatt 01</span>"
    ]
  },
  {
    "objectID": "sh01/01.html#footnotes",
    "href": "sh01/01.html#footnotes",
    "title": "1  Blatt 01",
    "section": "",
    "text": "https://www.wikiwand.com/en/articles/X86-64↩︎\nhttps://www.wikiwand.com/en/articles/Advanced_Vector_Extensions↩︎",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Blatt 01</span>"
    ]
  },
  {
    "objectID": "sh02/02.html",
    "href": "sh02/02.html",
    "title": "2  Blatt 02",
    "section": "",
    "text": "Aufgabe 1\nDie Datenstruktur task_struct ist im Linux-Kernel-Quellcode (Linux kernel Version 6.15.0) definiert unter:\ninclude/linux/sched.h\nDie Definition erstreckt sich über die Zeilen 813 bis 1664.\nDarin befinden sich etwa 320 Member-Variablen.\nBei einer Annahme von 8 Byte pro Variable ergibt sich eine geschätzte Größe von:\n2.560 Byte \\(\\approx\\) 2,5 KB",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Blatt 02</span>"
    ]
  },
  {
    "objectID": "sh02/02.html#aufgabe-2",
    "href": "sh02/02.html#aufgabe-2",
    "title": "2  Blatt 02",
    "section": "Aufgabe 2",
    "text": "Aufgabe 2\nDer Systemaufruf fork() erzeugt einen neuen Prozess, der eine Kopie des aufrufenden Prozesses ist (Kindprozess).\nRückgabewert:\n\n0 im Kindprozess\n\nPID des Kindes im Elternprozess\n\n−1 bei Fehler\n\n\nMit dem program:\n#include &lt;stdio.h&gt;\n\nint main(int argc, char const *argv[])\n{\n    int i = 0;\n    if (fork() != 0) i++;\n    if (i != 1) fork();\n    fork();\n    return 0;\n}\nwerden insgesammt 6 Prozesse erzeugt. Graph der enstehenden Prozess hierarchie:\nP1  \n├── P1.1  \n│   └── P1.1.1  \n│       └── P1.1.1.1  \n│   └── P1.1.2  \n└── P1.2  \nSchrittweise Erzeugung der Prozesse:\n\nP1 startet das Programm. Der Wert von i ist anfangs 0.\nDie erste fork()-Anweisung wird ausgeführt:\n\nP1 ist der Elternprozess, der einen neuen Kindprozess P1.1 erzeugt.\nIm Elternprozess (P1) ist das Rückgabewert von fork() ≠ 0 → i wird auf 1 gesetzt.\nIm Kindprozess (P1.1) ist das Rückgabewert 0 → i bleibt 0.\n\nDanach folgt die Bedingung if (i != 1) fork();:\n\nP1 hat i == 1 → keine Aktion.\nP1.1 hat i == 0 → führt eine fork() aus → erzeugt P1.1.1.\n\nSchließlich wird eine letzte fork(); von allen existierenden Prozessen ausgeführt:\n\nP1 erzeugt P1.2\nP1.1 erzeugt P1.1.2\nP1.1.1 erzeugt P1.1.1.1\n\n\n\nDas Programm führt fork() aus, bis ein Kindprozess mit einer durch 10 teilbaren PID entsteht. Jeder fork() erzeugt ein Kind, das sofort endet (die Rückgabe von fork() is 0 bei einem Kind), außer die Bedingung ist erfüllt. Da etwa jede zehnte PID durch 10 teilbar ist, liegt die maximale Prozessanzahl (inkl. Elternprozess) typischerweise bei etwa 11.\nDa PIDs vom Kernel in aufsteigender Reihenfolge als nächste freie Zahl vergeben werden, ist garantiert, dass früher oder später eine durch 10 teilbare PID erzeugt wird. Das Programm terminiert daher immer. Wären PIDs zufällig, könnte es theoretisch unendlich laufen.\nStartende oder endende Prozesse können die PID-Vergabe beeinflussen, da sie die Reihenfolge freier PIDs verändern – dadurch variiert die genaue Prozessanzahl je nach Systemzustand.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Blatt 02</span>"
    ]
  },
  {
    "objectID": "sh02/02.html#aufgabe-3",
    "href": "sh02/02.html#aufgabe-3",
    "title": "2  Blatt 02",
    "section": "Aufgabe 3",
    "text": "Aufgabe 3\n\nErklärung zur Ausgabe von ps -T -H\nDas C-Programm:\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;unistd.h&gt;\n\nint main(int argc, char const *argv[])\n{\n    if (fork() &gt; 0) sleep(1000);\n    else exit(0);\n    return 0;\n}\nerzeugt einen Kindprozess. Das Kind beendet sich sofort (exit(0)), während der Elternprozess 1000 Sekunden schläft (sleep(1000)).\nAblauf der Kommandos:\n\nDas Ausführen von ./test &:\n\nDas Programm läuft im Hintergrund.\nDie Shell gibt [1] 136620 aus → Prozess-ID (PID) 136620.\nDer Kindprozess wird erzeugt und terminiert sofort.\nDer Elternprozess schläft weiter.\nDa wait() nicht aufgerufen wird, wird der Kindprozess zu einem Zombie-Prozess.\n\nDas Ausführen von ./test und das drücken von &lt;Strg&gt;+Z danach:\n\nDas Programm startet im Vordergrund.\nMit &lt;Strg&gt;+Z wird es gestoppt.\nDie Shell zeigt: [2]+  Stopped ./test.\nAuch hier terminiert der Kindprozess sofort → Zombie-Prozess entsteht erneut.\n\n\nAusgabe von ps -T -H:\n    PID TTY      STAT   TIME COMMAND\n   1025 pts/0    Ss     0:00 /bin/bash --posix\n 136620 pts/0    S      0:00   ./test\n 136621 pts/0    Z      0:00     [test] &lt;defunct&gt;\n 136879 pts/0    T      0:00   ./test\n 136880 pts/0    Z      0:00     [test] &lt;defunct&gt;\n 136989 pts/0    R+     0:00   ps T -H\nErklärung:\n\n1025: Die Shell (bash), läuft im Terminal pts/0.\n136620: Erstes ./test-Programm, läuft im Hintergrund, schläft (S).\n136621: Dessen Kindprozess (Zombie, Z), da exit() aufgerufen wurde, aber vom Elternprozess nicht abgeholt.\n136879: Zweites ./test-Programm, wurde mit &lt;Strg+Z&gt; gestoppt (T).\n136880: Auch hier: Kindprozess wurde beendet, aber nicht „abgeholt“ → Zombie.\n136989: Der ps-Prozess selbst, der gerade die Ausgabe erzeugt (R+ = laufend im Vordergrund).\n\nDie Spalten\n\nPID: Prozess-ID.\nTTY: Terminal, dem der Prozess zugeordnet ist.\nSTAT: Prozessstatus:\n\nS: sleeping – schläft.\nT: stopped – gestoppt (z. B. durch SIGSTOP).\nZ: zombie – beendet, aber noch nicht „aufgeräumt“.\nR: running – aktuell laufend auf der CPU.\n+: Teil der Vordergrund-Prozessgruppe im Terminal.\n\nTIME: CPU-Zeit, die der Prozess verbraucht hat.\nCOMMAND: Der auszuführende Befehl.\n\n[test] &lt;defunct&gt; heißt, es handelt sich um einen Zombie-Prozess, dessen Kommandozeile nicht mehr verfügbar ist.\n\n\n\n\nProcess state Codes\nProzesszustände (erste Buchstaben):\n\n\n\n\n\n\n\n\nCode\nMeaning\nDescription\n\n\n\n\nR\nRunning\nCurrently running or ready to run (on CPU)\n\n\nS\nSleeping\nWaiting for an event (e.g., input, timer)\n\n\nD\nUninterruptible sleep\nWaiting for I/O (e.g., disk), cannot be killed easily\n\n\nT\nStopped\nProcess has been stopped (e.g., SIGSTOP, Ctrl+Z)\n\n\nZ\nZombie\nTerminated, but not yet cleaned up by its parent\n\n\nX\nDead\nProcess is terminated and should be gone (rarely shown)\n\n\n\nZusätzliche flags:\n\n\n\nFlag\nMeaning\n\n\n\n\n&lt;\nHigh priority (not nice to others)\n\n\nN\nLow priority (nice value &gt; 0)\n\n\nL\nHas pages locked in memory\n\n\ns\nSession leader\n\n\n+\nIn the foreground process group\n\n\nl\nMulti-threaded (using CLONE_THREAD)\n\n\np\nIn a separate process group\n\n\n\nZ.B. Ss+ beduetet: Sleeping (S), Session leader (s) & Foreground process (+).\n\n\nTiefe der Aktuellen Sitzung\nZuerst finden wir die PID der Aktuellen sitzung mit\necho $$\nheraus. Output: 1025.\nDanch führen wir das Command ps -eH | less aus und suchen im pager nach “1025”. In unserer Sitzung befand sich “bash” unter der Hierarchie:\n1 systemd\n    718 ssdm\n        766 ssdm-helper\n            859 i3\n                884 kitty\n                    1025 bash\nDas entspricht der Tiefe 5 des Prozessbaums.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Blatt 02</span>"
    ]
  },
  {
    "objectID": "sh02/02.html#aufgabe-4",
    "href": "sh02/02.html#aufgabe-4",
    "title": "2  Blatt 02",
    "section": "Aufgabe 4",
    "text": "Aufgabe 4\nÜbersicht der Varianten mit Signaturen:\n\n\n\n\n\n\n\nFunktion\nSignatur\n\n\n\n\nexecl\nint execl(const char *path, const char *arg0, ..., NULL);\n\n\nexecle\nint execle(const char *path, const char *arg0, ..., NULL, char *const envp[]);\n\n\nexeclp\nint execlp(const char *file, const char *arg0, ..., NULL);\n\n\nexecv\nint execv(const char *path, char *const argv[]);\n\n\nexecvp\nint execvp(const char *file, char *const argv[]);\n\n\nexecvpe\nint execvpe(const char *file, char *const argv[], char *const envp[]);\n\n\nexecve\nint execve(const char *filename, char *const argv[], char *const envp[]);\n\n\n\nWichtige Unterschiede:\n\nl = Argumente als Liste (z. B. execl)\nv = Argumente als Array (vector) (z. B. execv)\np = PATH-Suche aktiv (z. B. execvp)\ne = eigene Umgebung (envp[]) möglich (z. B. execle, execvpe)\nKein p = voller Pfad zur Datei nötig\nKein e = aktuelle Umgebungsvariablen werden übernommen\n\nWann welche Variante?\n\n\n\n\n\n\n\nVariante\nTypischer Einsatzzweck\n\n\n\n\nexecl\nFester Pfad und Argumente direkt im Code als Liste\n\n\nexecle\nWie execl, aber mit eigener Umgebung\n\n\nexeclp\nWie execl, aber PATH-Suche aktiviert (z. B. ls statt /bin/ls)\n\n\nexecv\nPfad bekannt, Argumente liegen als Array vor (z. B. aus main)\n\n\nexecvp\nWie execv, aber mit PATH-Suche (typisch für Shells)\n\n\nexecvpe\nWie execvp, aber mit eigener Umgebung (GNU-spezifisch)\n\n\nexecve\nLow-Level, volle Kontrolle über Pfad, Argumente und Umgebung",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Blatt 02</span>"
    ]
  },
  {
    "objectID": "sh02/02.html#aufgabe-5",
    "href": "sh02/02.html#aufgabe-5",
    "title": "2  Blatt 02",
    "section": "Aufgabe 5",
    "text": "Aufgabe 5\nEin Prozesswechsel (Context Switch) tritt auf, wenn das Betriebssystem (OS) die Ausführung eines Prozesses stoppt und zu einem anderen wechselt. Dabei entsteht Overhead, weil:\n\nDer aktuelle CPU-Zustand (Register, Programmzähler etc.) gespeichert werden muss\nDieser Zustand im Prozesskontrollblock (PCB) abgelegt wird\nDer Zustand des neuen Prozesses aus seinem PCB geladen wird\nDie Speicherverwaltungsstrukturen (z. B. Seitentabellen der MMU) aktualisiert werden müssen\nDer TLB (Translation Lookaside Buffer) meist ungültig wird und geleert werden muss\nWeitere OS-Daten wie Datei-Deskriptoren oder Signale angepasst werden müssen\n\nDer PCB enthält:\n\nProzess-ID, Zustand\nRegister, Programmzähler\nSpeicherinfos, geöffnete Dateien\nScheduling-Infos\n\nBeim Prozesswechsel speichert das OS den PCB des alten Prozesses und lädt den neuen, um eine korrekte Fortsetzung zu ermöglichen. Da jeder Prozess einen eigenen Adressraum besitzt, ist der Aufwand für das Umschalten entsprechend hoch.\nThreads desselben Prozesses teilen sich hingegen denselben Adressraum (also denselben Code, Heap, offene Dateien etc.). Das bedeutet:\n\nEs ist kein Wechsel des Adressraums nötig\nDie MMU- und TLB-Einträge bleiben gültig\nNur der Thread-spezifische Kontext (Register, Stack-Pointer etc.) muss gespeichert werden\n\nFazit: Ein Threadwechsel ist viel leichter und schneller**, da kein teurer Speicherverwaltungswechsel nötig ist.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Blatt 02</span>"
    ]
  },
  {
    "objectID": "sh02/02.html#aufgabe-6",
    "href": "sh02/02.html#aufgabe-6",
    "title": "2  Blatt 02",
    "section": "Aufgabe 6",
    "text": "Aufgabe 6\n\nIn der ursprünglichen Version werden alle Threads schnell hintereinander gestartet, ohne aufeinander zu warten. Da die Ausführung der Threads vom Scheduler (Betriebssystem) abhängt und parallel erfolgt, kann die Ausgabe beliebig vermischt erscheinen – z. B. kann ein Thread seine Nachricht „number: i“ ausgeben, noch bevor die Hauptfunktion „creating thread i“ gedruckt hat.\nIn der überarbeiteten Version hingegen wird jeder Thread direkt nach dem Start mit pthread_join wieder eingesammelt. Dadurch läuft immer nur ein Thread zur Zeit, und seine Ausgabe erfolgt vollständig, bevor der nächste beginnt. So entsteht eine streng sequentielle Ausgabe:\n\n„creating thread i“\n„number: i“\n„ending thread i“\n\nDiese einfache Struktur vermeidet Race Conditions und benötigt keine zusätzlichen Synchronisationsmechanismen wie Semaphoren oder Locks.\nÜberarbeitete Version (auch im zip als threads_example.c enthalten):\n\n\nthreads_example.c\n\n#include &lt;pthread.h&gt;\n#include &lt;stdio.h&gt; \n#include &lt;stdlib.h&gt;\n#include &lt;assert.h&gt;\n\n#define NUM_THREADS 200000\n\nvoid* TaskCode (void* argument)\n{\n   int tid = *((int*) argument);\n   printf(\"number: %d\\n\", tid);\n   printf(\"ending thread %d\\n\", tid);\n   return NULL;\n}\n\nint main()\n{\n   pthread_t thread;\n   int thread_arg;\n\n   for (int i = 0; i &lt; NUM_THREADS; i++) {\n      thread_arg = i;\n      printf(\"creating thread %d\\n\", i);\n      int rc = pthread_create(&thread, NULL, TaskCode, &thread_arg);\n      assert(rc == 0);\n      rc = pthread_join(thread, NULL);\n      assert(rc == 0);\n   }\n\n   return 0;\n}\n\nIn unserem System \\(N_{\\text{max}} \\approx 200000\\).\nIm folgenden Program wird TaskCode() \\(N_\\text{max}\\) mal in einer einfachen Schleife aufgerufen:\n#include &lt;pthread.h&gt;\n#include &lt;stdio.h&gt; \n#include &lt;stdlib.h&gt;\n#include &lt;assert.h&gt;\n\n#define NUM_THREADS 200000\n\nvoid* TaskCode (void* argument)\n{\n   int tid = *((int*) argument);\n   printf(\"number: %d\\n\", tid);\n   printf(\"ending thread %d\\n\", tid);\n   return NULL;\n}\n\nint main()\n{\n   for (int i = 0; i &lt; NUM_THREADS; i++) {\n      TaskCode(&i);\n   }\n\n   return 0;\n}\nDie Ausführung dieses Programs dauerte c. 2 Sekunden auf unserem System. D.h. die fehlenden zwei pthread_* aufrufe kosten\n\n8 Sekunden für 200000 Schleifen. Das entspricht c. 20 millisekunden pro pthread_* Aufruf.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Blatt 02</span>"
    ]
  },
  {
    "objectID": "sh03/03.html",
    "href": "sh03/03.html",
    "title": "3  Blatt 03",
    "section": "",
    "text": "Aufgabe 1\nErklärung:\nDieses Programm vermeidet das Race Condition-Problem, indem beide Threads einen synchronized-Block verwenden, der auf Counter.class synchronisiert ist. Das bedeutet:",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Blatt 03</span>"
    ]
  },
  {
    "objectID": "sh03/03.html#aufgabe-1",
    "href": "sh03/03.html#aufgabe-1",
    "title": "3  Blatt 03",
    "section": "",
    "text": "Die Ausgabe ist inkonsistent – bei mehreren Programmausführungen erscheinen unterschiedliche Werte für counter. Dies liegt an einer Race Condition, da beide Threads gleichzeitig und ohne Synchronisation auf die gemeinsame Variable counter zugreifen. Dadurch können Zwischenergebnisse überschrieben oder verloren gehen, je nachdem, wie der Scheduler die Threads abwechselnd ausführt.\nSynchronisierte Lösung (Java-Code):\n\npublic class Counter {\n    static int counter = 0;\n\n    public static class Counter_Thread_A extends Thread {\n        public void run() {\n            synchronized (Counter.class) {\n                counter = 5;\n                counter++;\n                counter++;\n                System.out.println(\"A-Counter: \" + counter);\n            }\n        }\n    }\n\n    public static class Counter_Thread_B extends Thread {\n        public void run() {\n            synchronized (Counter.class) {\n                counter = 6;\n                counter++;\n                counter++;\n                counter++;\n                counter++;\n                System.out.println(\"B-Counter: \" + counter);\n            }\n        }\n    }\n\n    public static void main(String[] args) {\n        Thread a = new Counter_Thread_A();\n        Thread b = new Counter_Thread_B();\n        a.start();\n        b.start();\n    }\n}\n\n\n\nNur ein Thread darf gleichzeitig den Block betreten.\nDer andere Thread muss warten, bis der erste fertig ist und den Lock freigibt.\nDadurch wird sichergestellt, dass keine gleichzeitigen Zugriffe auf die gemeinsame Variable counter stattfinden.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Blatt 03</span>"
    ]
  },
  {
    "objectID": "sh03/03.html#aufgabe-3",
    "href": "sh03/03.html#aufgabe-3",
    "title": "3  Blatt 03",
    "section": "Aufgabe 3",
    "text": "Aufgabe 3\n\nUnten folgt der Quellcode zur verbesserten Lösung des Producer-Consumer-Problems (pc2.c am Ende des Dokuments). In dieser Version wird Busy Waiting durch eine effiziente Synchronisation mithilfe eines Mutexes und einer Condition Variable ersetzt.\nDer Code befindet sich auch im beigefügten Zip-Archiv im Ordner A3. Dort kann das Programm wie folgt kompiliert und ausgeführt werden:\n\nmake  \n./pc2\nDiese Implementierung gewährleistet eine korrekte und effiziente Koordination zwischen Producer- und Consumer-Threads:\n\nDie gemeinsame Warteschlange wird durch einen Mutex geschützt.\nThreads, die auf eine Bedingung warten, verwenden pthread_cond_wait() innerhalb einer while-Schleife, um Spurious Wakeups korrekt zu behandeln.\nIst die Warteschlange leer, schlafen die Consumer, bis sie ein Signal erhalten; ist sie voll, wartet der Producer entsprechend.\nDurch das gezielte Aufwecken via pthread_cond_signal() oder pthread_cond_broadcast() wird unnötiger CPU-Verbrauch durch aktives Warten vermieden.\n\nInsgesamt ist diese Lösung robuster und skalierbarer als die ursprüngliche Variante mit Busy Waiting – insbesondere bei mehreren Consumer-Threads und höherer Auslastung.\n\n\n\npc2.c\n\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;pthread.h&gt;\n#include \"mylist.h\"\n// Mutex to protect access to the shared queue\npthread_mutex_t queue_lock;\n// Single condition variable used for both producers and consumers\npthread_cond_t cond_var;\n// Shared buffer (a custom linked list acting as a queue)\nlist_t buffer;\n// Counters for task management\nint count_proc = 0;\nint production_done = 0;\n/********************************************************/\n/* Function Declarations */\nstatic unsigned long fib(unsigned int n);\nstatic void create_data(elem_t **elem);\nstatic void *consumer_func(void *);\nstatic void *producer_func(void *);\n/********************************************************/\n/* Compute the nth Fibonacci number (CPU-intensive task) */\nstatic unsigned long fib(unsigned int n)\n{\n    if (n == 0 || n == 1) {\n        return n;\n    } else {\n        return fib(n - 1) + fib(n - 2);\n    }\n}\n/* Allocate and initialize a new task node */\nstatic void create_data(elem_t **elem)\n{\n    *elem = (elem_t*) malloc(sizeof(elem_t));\n    (*elem)-&gt;data = FIBONACCI_MAX;\n}\n/* Consumer thread function */\nstatic void *consumer_func(void *args) \n{\n    elem_t *elem;\n    while (1) {\n        pthread_mutex_lock(&queue_lock);\n        // Wait if the queue is empty and production is not yet complete\n        while (get_size(&buffer) == 0 && !production_done) {\n            pthread_cond_wait(&cond_var, &queue_lock);\n        }\n        // Exit condition: queue is empty and production has finished\n        if (get_size(&buffer) == 0 && production_done) {\n            pthread_mutex_unlock(&queue_lock);\n            break;\n        }\n        // Remove an item from the queue\n        remove_elem(&buffer, &elem);\n        // Wake up a potentially waiting producer\n        pthread_cond_signal(&cond_var);\n        pthread_mutex_unlock(&queue_lock);\n        // Process the task\n        fib(elem-&gt;data);\n        free(elem);\n        printf(\"item consumed\\n\");\n    }\n    return NULL;\n}\n/* Producer thread function */\nstatic void *producer_func(void *args) \n{\n    while (1) {\n        pthread_mutex_lock(&queue_lock);\n        // Wait if the buffer is full\n        while (get_size(&buffer) &gt;= MAX_QUEUE_LENGTH) {\n            pthread_cond_wait(&cond_var, &queue_lock);\n        }\n        if (count_proc &lt; MAX_COUNT) {\n            // Create and append a new task to the queue\n            elem_t *elem;\n            create_data(&elem);\n            append_elem(&buffer, elem);\n            count_proc++;\n            printf(\"item produced\\n\");\n            // Wake up one waiting consumer\n            pthread_cond_signal(&cond_var);\n        }\n        // If production is done, notify all consumers and exit\n        if (count_proc &gt;= MAX_COUNT) {\n            production_done = 1;\n            // Wake up all consumers waiting on cond_var so they can check the exit condition\n            pthread_cond_broadcast(&cond_var);\n            pthread_mutex_unlock(&queue_lock);\n            break;\n        }\n        pthread_mutex_unlock(&queue_lock);\n    }\n    return NULL;\n}\n/* Main function */\nint main (int argc, char *argv[])\n{\n    pthread_t cons_thread[NUM_CONSUMER];\n    pthread_t prod_thread;\n    int i;\n    // Initialize mutex and condition variable\n    pthread_mutex_init(&queue_lock, NULL);\n    pthread_cond_init(&cond_var, NULL);\n    init_list(&buffer);\n    // Start consumer threads\n    for (i = 0; i &lt; NUM_CONSUMER; i++) {\n        pthread_create(&cons_thread[i], NULL, &consumer_func, NULL);\n    }\n    // Start producer thread\n    pthread_create(&prod_thread, NULL, &producer_func, NULL);\n\n    // Wait for all consumer threads to finish\n    for (i = 0; i &lt; NUM_CONSUMER; i++) {\n        pthread_join(cons_thread[i], NULL);\n    }\n    // Wait for producer thread to finish\n    pthread_join(prod_thread, NULL);\n    // Cleanup\n    pthread_mutex_destroy(&queue_lock);\n    pthread_cond_destroy(&cond_var);\n    return 0;\n}\n\n\n\nLaufzeitvergleich von pc und pc2\nZur Überprüfung der Effizienzverbesserung durch den Einsatz von Condition Variables wurde folgendes Bash-Skript verwendet, das beide Programme je 10-mal ausführt und die durchschnittliche Laufzeit berechnet:\n#!/bin/bash\n\nRUNS=10\nPC=\"./pc\"\nPC2=\"./pc2\"\n\nmeasure_average_runtime() {\n    PROGRAM=$1\n    TOTAL=0\n    echo \"Running $PROGRAM...\"\n    for i in $(seq 1 $RUNS); do\n        START=$(date +%s.%N)\n        $PROGRAM &gt; /dev/null\n        END=$(date +%s.%N)\n        RUNTIME=$(echo \"$END - $START\" | bc)\n        echo \"  Run $i: $RUNTIME seconds\"\n        TOTAL=$(echo \"$TOTAL + $RUNTIME\" | bc)\n    done\n    AVG=$(echo \"scale=4; $TOTAL / $RUNS\" | bc)\n    echo \"Average runtime of $PROGRAM: $AVG seconds\"\n    echo\n}\n\necho \"Measuring $RUNS runs of $PC and $PC2...\"\necho\nmeasure_average_runtime $PC\nmeasure_average_runtime $PC2\nAusgeführt wurde das Skript mit:\n./benchmark_pc.sh\nDabei ergaben sich folgende Laufzeiten:\nMeasuring 10 runs of ./pc and ./pc2...\n\nRunning ./pc...\n  Run 1: 5.471139729 seconds\n  Run 2: 5.545249360 seconds\n  Run 3: 5.359090183 seconds\n  Run 4: 5.366634866 seconds\n  Run 5: 5.459910579 seconds\n  Run 6: 5.531161091 seconds\n  Run 7: 5.738575161 seconds\n  Run 8: 5.835055657 seconds\n  Run 9: 5.496744966 seconds\n  Run 10: 5.641529848 seconds\nAverage runtime of ./pc: 5.5445 seconds\n\nRunning ./pc2...\n  Run 1: 5.244080521 seconds\n  Run 2: 5.237442233 seconds\n  Run 3: 5.220517776 seconds\n  Run 4: 5.281094089 seconds\n  Run 5: 5.261722379 seconds\n  Run 6: 5.363685993 seconds\n  Run 7: 5.276107150 seconds\n  Run 8: 5.091557858 seconds\n  Run 9: 5.073267276 seconds\n  Run 10: 5.164472482 seconds\nAverage runtime of ./pc2: 5.2213 seconds\nDie Ergebnisse zeigen, dass pc2 im Schnitt etwas schneller ist als pc (5.22 s gegenüber 5.54 s), was den Effizienzgewinn durch den Verzicht auf aktives Warten bestätigt.\nDie Dateien benchmark_pc.sh und benchmark_results.txt befinden sich im Ordner A3 des ZIP-Archivs.\nZur Veranschaulichung wurde mit dem folgendnen Python script zusätzlich ein Diagramm erstellt, das die Laufzeiten von pc und pc2 über zehn Durchläufe hinweg zeigt. Die Durchschnittslinien verdeutlichen, dass pc2 im Mittel schneller und konsistenter ist als pc.\n\nimport matplotlib.pyplot as plt\n\n# Runtime data for each run (in seconds)\npc = [5.471139729, 5.545249360, 5.359090183, 5.366634866, 5.459910579,\n      5.531161091, 5.738575161, 5.835055657, 5.496744966, 5.641529848]\n\npc2 = [5.244080521, 5.237442233, 5.220517776, 5.281094089, 5.261722379,\n       5.363685993, 5.276107150, 5.091557858, 5.073267276, 5.164472482]\n\n# X-axis: run numbers\nruns = list(range(1, 11))\n\n# Calculate averages\navg_pc = sum(pc) / len(pc)\navg_pc2 = sum(pc2) / len(pc2)\n\n# Plot configuration\nplt.figure(figsize=(10, 6))\nplt.plot(runs, pc, marker='o', label='pc')\nplt.plot(runs, pc2, marker='o', label='pc2')\n\n# Average lines\nplt.axhline(avg_pc, color='red', linestyle='--', label=f'avg pc ({avg_pc:.3f}s)')\nplt.axhline(avg_pc2, color='green', linestyle='--', label=f'avg pc2 ({avg_pc2:.3f}s)')\n\n# Labels and title\nplt.xlabel('Run')\nplt.ylabel('Time (s)')\nplt.title('Runtime Comparison of pc vs. pc2')\nplt.xticks(runs)\nplt.grid(True)\nplt.legend()\nplt.tight_layout()\n\n# Display the plot\nplt.show()",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Blatt 03</span>"
    ]
  },
  {
    "objectID": "sh03/03.html#aufgabe-4",
    "href": "sh03/03.html#aufgabe-4",
    "title": "3  Blatt 03",
    "section": "Aufgabe 4",
    "text": "Aufgabe 4\n\nDie gegebene Implementierung kann zu einer Verletzung des gegenseitigen Ausschlusses führen, wenn zwei schreibende Threads gleichzeitig in die kritische Sektion gelangen.\nBeispiel: Angenommen N = 5. Thread A und Thread B rufen gleichzeitig lock_write() auf. Da der for-Loop nicht durch einen Mutex geschützt ist, können sich ihre wait(S)-Aufrufe gegenseitig durchmischen: A nimmt 1 Token → S = 4 B nimmt 1 Token → S = 3 A nimmt 1 → S = 2 B nimmt 1 → S = 1 … und so weiter. Wenn nun zufällig genug Tokens freigegeben werden (z. B. durch unlock_read()-Aufrufe), können beide Threads nacheinander die restlichen Semaphore erwerben und ihren Loop abschließen, ohne dass einer von ihnen jemals alle N Tokens exklusiv gehalten hat. Beide betreten anschließend die kritische Sektion, obwohl gegenseitiger Ausschluss nicht mehr gewährleistet ist.\nDas Problem wird behoben, indem ein zusätzlicher Mutex eingeführt wird, der verhindert, dass mehrere schreibende Threads gleichzeitig versuchen, die Semaphore S zu erwerben:\nS = Semaphore(N)\nM = Semaphore(1)  // neuer Mutex\n\ndef lock_read():\n    wait(S)\n\ndef unlock_read():\n    signal(S)\n\ndef lock_write():\n    wait(M)\n    for i in range(N): wait(S)\n    signal(M)\n\ndef unlock_write():\n    for i in range(N): signal(S)\nDurch den Mutex M ist sichergestellt, dass der Erwerb der Semaphore in lock_write() ausschließlich von einem Thread durchgeführt wird. So wird verhindert, dass mehrere schreibende Threads gleichzeitig in die kritische Sektion gelangen.\nHinweis: Diese Lösung stellt den gegenseitigen Ausschluss sicher, erlaubt jedoch theoretisch, dass ein schreibender Thread dauerhaft blockiert bleibt, wenn ständig neue Leser auftreten (Starvation). Für diese Aufgabe ist jedoch nur die Korrektur der Ausschlussverletzung relevant.\nDie Befehle upgrade_to_write() und downgrade_to_read() ermöglichen es einem Thread, während des laufenden Zugriffs die Art des Read-Write-Locks dynamisch zu wechseln – ohne dabei den kritischen Abschnitt vollständig zu verlassen. Dies verhindert Race Conditions und potenzielle Starvation.\nEin Thread, der upgrade_to_write() aufruft, hält bereits einen Lesezugriff (also eine Einheit der Semaphore S) und möchte exklusiven Schreibzugriff erhalten. Dafür müssen die verbleibenden N - 1 Einheiten erworben werden. Ein zusätzlicher Mutex M sorgt dafür, dass nicht mehrere Threads gleichzeitig versuchen, sich hochzustufen, was zu Deadlocks führen könnte.\nEin Thread, der downgrade_to_read() aufruft, hält alle N Einheiten (Schreibzugriff) und möchte auf geteilten Lesezugriff wechseln. Dazu werden N - 1 Einheiten freigegeben – eine Einheit bleibt erhalten.\nHinweis: Das hier verwendete Mutex M ist dasselbe wie in Teil b) und stellt sicher, dass nur ein Thread gleichzeitig exklusiven Zugriff auf die Semaphore S erwerben kann – sei es über lock_write() oder über upgrade_to_write().\nPseudocode:\nS = Semaphore(N)     // erlaubt bis zu N gleichzeitige Leser oder 1 Schreiber\nM = Semaphore(1)     // schützt exklusive Zugriffsversuche\n\ndef upgrade_to_write():\n    wait(M)\n    for i in range(N - 1):     // hält bereits 1 Einheit als Leser\n        wait(S)\n    signal(M)\n\ndef downgrade_to_read():\n    for i in range(N - 1):     // gibt N - 1 Einheiten frei, behält 1\n        signal(S)\nFazit: Diese Operationen garantieren einen sicheren Übergang zwischen Lese- und Schreibmodus, ohne Race Conditions oder Deadlocks, und basieren auf derselben Semaphor-Struktur wie in Teil b).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Blatt 03</span>"
    ]
  },
  {
    "objectID": "sh04/04.html",
    "href": "sh04/04.html",
    "title": "4  Blatt 04",
    "section": "",
    "text": "Aufgabe 1",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Blatt 04</span>"
    ]
  },
  {
    "objectID": "sh04/04.html#aufgabe-1",
    "href": "sh04/04.html#aufgabe-1",
    "title": "4  Blatt 04",
    "section": "",
    "text": "Ein Nachteil benannter Pipes ist, dass sie manuell im Dateisystem erstellt und verwaltet werden müssen (z. B. mit mkfifo). Das macht die Handhabung aufwändiger und erfordert gegebenenfalls zusätzliche Aufräummaßnahmen.\nWenn zwei voneinander unabhängige Prozesse (z. B. zwei Terminals) Daten austauschen sollen, ist eine benannte Pipe erforderlich. Anonyme Pipes funktionieren nur zwischen verwandten Prozessen (z. B. Eltern-Kind).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Blatt 04</span>"
    ]
  },
  {
    "objectID": "sh04/04.html#aufgabe-2",
    "href": "sh04/04.html#aufgabe-2",
    "title": "4  Blatt 04",
    "section": "Aufgabe 2",
    "text": "Aufgabe 2\n\nIm Win32-API ist ein Handle vom Typ:\ntypedef void* HANDLE;\nEs handelt sich also um einen Zeiger (bzw. zeigerbreiten Wert), der jedoch nicht dereferenziert werden soll. Ein Handle ist ein undurchsichtiger Verweis auf eine Ressource, die vom Windows-Kernel verwaltet wird – etwa eine Datei, ein Prozess, ein Event oder ein Fensterobjekt.\nWenn ein Programm zum Beispiel CreateFile() aufruft, gibt der Kernel einen solchen Handle zurück. Dieser verweist intern auf ein Objekt in der Handle-Tabelle des Prozesses. Diese Tabelle enthält Informationen wie Zugriffsrechte, aktuelle Dateiposition, Typ des Objekts usw.\nIm Unterschied zu Dateideskriptoren unter Unix/Linux (einfache Ganzzahlen) sind Win32-Handles allgemeiner gehalten und dienen zum Zugriff auf viele verschiedene Ressourcentypen – nicht nur auf Dateien.\nDie Umleitung der Standardausgabe erfolgt im Win32-API in zwei Schritten:\n\nEine Datei wird mit CreateFile() geöffnet oder erzeugt.\nDer Handle für STD_OUTPUT_HANDLE wird mit SetStdHandle() auf diesen Datei-Handle gesetzt.\n\nBeispiel:\n#include &lt;windows.h&gt;\n#include &lt;stdio.h&gt;\n\nint main() {\n    HANDLE hFile = CreateFile(\"output.txt\", GENERIC_WRITE, 0, NULL,\n                              CREATE_ALWAYS, FILE_ATTRIBUTE_NORMAL, NULL);\n\n    if (hFile == INVALID_HANDLE_VALUE) {\n        printf(\"Fehler beim Öffnen der Datei.\\n\");\n        return 1;\n    }\n\n    // Standardausgabe umleiten\n    SetStdHandle(STD_OUTPUT_HANDLE, hFile);\n\n    // Alles, was an STD_OUTPUT_HANDLE geschrieben wird, geht nun in die Datei\n    DWORD written;\n    WriteFile(GetStdHandle(STD_OUTPUT_HANDLE),\n              \"Hello redirected world!\\n\", 24, &written, NULL);\n\n    CloseHandle(hFile);\n    return 0;\n}\nDiese Umleitung wirkt sich auf Low-Level-Funktionen wie WriteFile() aus. Wenn man dagegen höhere Funktionen wie printf() oder std::cout umleiten will, muss zusätzlich die Laufzeitumgebung angepasst werden – etwa mit freopen() oder std::ios-Umleitungen.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Blatt 04</span>"
    ]
  },
  {
    "objectID": "sh04/04.html#aufgabe-3",
    "href": "sh04/04.html#aufgabe-3",
    "title": "4  Blatt 04",
    "section": "Aufgabe 3",
    "text": "Aufgabe 3\nDas Program: (Auch im Zip unter dem Verzeichniss A3 als reverse_pipechat.c enthalten)\n\n\nreverse_pipechat.c\n\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;unistd.h&gt;\n#include &lt;string.h&gt;\n#include &lt;sys/wait.h&gt;\n\n#define BUFFER_SIZE 1024\n\n// Utility: reverse a string in place\nvoid reverse_string(char *str) {\n    int len = strlen(str);\n    for (int i = 0; i &lt; len / 2; ++i) {\n        char tmp = str[i];\n        str[i] = str[len - 1 - i];\n        str[len - 1 - i] = tmp;\n    }\n}\n\nint main() {\n    int pipe_a_to_b[2]; // parent writes to child\n    int pipe_b_to_a[2]; // child writes to parent\n\n    if (pipe(pipe_a_to_b) == -1 || pipe(pipe_b_to_a) == -1) {\n        perror(\"pipe\");\n        exit(EXIT_FAILURE);\n    }\n\n    pid_t pid = fork();\n\n    if (pid &lt; 0) {\n        perror(\"fork\");\n        exit(EXIT_FAILURE);\n    }\n    else if (pid == 0) {\n        // Child process: Process B\n        close(pipe_a_to_b[1]); // Close write end of A→B\n        close(pipe_b_to_a[0]); // Close read end of B→A\n\n        char buffer[BUFFER_SIZE];\n\n        // Read message from parent\n        ssize_t bytes_read = read(pipe_a_to_b[0], buffer, BUFFER_SIZE - 1);\n        if (bytes_read &lt;= 0) {\n            perror(\"child read\");\n            exit(EXIT_FAILURE);\n        }\n\n        buffer[bytes_read] = '\\0'; // Null-terminate the string\n\n        reverse_string(buffer); // Reverse the string\n\n        // Send it back to parent\n        write(pipe_b_to_a[1], buffer, strlen(buffer));\n\n        // Close used pipe ends\n        close(pipe_a_to_b[0]);\n        close(pipe_b_to_a[1]);\n\n        exit(EXIT_SUCCESS);\n    } else {\n        // Parent process: Process A\n        close(pipe_a_to_b[0]); // Close read end of A→B\n        close(pipe_b_to_a[1]); // Close write end of B→A\n\n        char input[BUFFER_SIZE];\n        printf(\"Enter a string: \");\n        if (!fgets(input, BUFFER_SIZE, stdin)) {\n            perror(\"fgets\");\n            exit(EXIT_FAILURE);\n        }\n\n        // Remove newline if present\n        input[strcspn(input, \"\\n\")] = '\\0';\n\n        // Send input to child\n        write(pipe_a_to_b[1], input, strlen(input));\n\n        char reversed[BUFFER_SIZE];\n        ssize_t bytes_received = read(pipe_b_to_a[0], reversed, BUFFER_SIZE - 1);\n        if (bytes_received &lt;= 0) {\n            perror(\"parent read\");\n            exit(EXIT_FAILURE);\n        }\n\n        reversed[bytes_received] = '\\0'; // Null-terminate\n\n        printf(\"Reversed string: %s\\n\", reversed);\n\n        // Close used pipe ends\n        close(pipe_a_to_b[1]);\n        close(pipe_b_to_a[0]);\n\n        wait(NULL); // Wait for child to finish\n    }\n\n    return 0;\n}\n\nDas C-Programm demonstriert die Kommunikation zwischen zwei Prozessen über anonyme Pipes. Der Elternprozess (A) liest eine Zeichenkette von der Standardeingabe und sendet sie an den Kindprozess (B). Dieser kehrt die Zeichenkette um und schickt sie zurück. Der Elternprozess gibt das Ergebnis anschließend auf der Standardausgabe aus.\nTechnisch funktioniert das Programm so: Es erstellt zwei Pipes – eine für die Kommunikation von A nach B, die andere für die Rückrichtung. Nach dem Aufruf von fork() schließt jeder Prozess die jeweils nicht benötigten Enden der Pipes. Der Elternprozess sendet die Benutzereingabe an das Kind, das die Zeichenkette verarbeitet und die Antwort zurückschickt. Beide Prozesse verwenden read() und write() zur Datenübertragung und beenden sich danach.\nKompilieren und ausführen kann man das Programm unter Verzeichniss A3 mit:\nmake\n./pipe_example\nBeispielausgabe:\nEnter a string: hallo welt\nReversed string: tlew ollah",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Blatt 04</span>"
    ]
  },
  {
    "objectID": "sh04/04.html#aufgabe-4",
    "href": "sh04/04.html#aufgabe-4",
    "title": "4  Blatt 04",
    "section": "Aufgabe 4",
    "text": "Aufgabe 4\n\n:\n\nFragmentiuerung: Intern. (Eine geringe Anzahl von langlebigen Objekten existieren in einem Page, was zur internen Speicherverschwendung führt)\nDefinition der Internen Fragmentierung (in diesem Kontext): Speicherverschwendung innerhalb der Seite\n\n\n\n\ntiming diagram\n\n\n:\n\nsehr häufig: fast immer handelt es sich um einen Tradeoff, z.B. beim best fit vs first fit handelt es sich um das Tradeoff Speichereffizienz vs Zeiteffizienz\nTradeoff: Cache misses vs Interne Fragmentierung (Zeit vs Speicherplatz)\n\nKleine Seiten: Wenig interne Fragmentierung aber häufige Cache misses \\(\\Rightarrow\\) Zeitverschwendung\nGrosse Seiten: Seltene Cach misses aber sehr große interne Fragmentierung (da es häufig langlebige Objekte existieren) \\(\\Rightarrow\\) Speicherverscwendung",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Blatt 04</span>"
    ]
  },
  {
    "objectID": "sh04/04.html#aufgabe-5",
    "href": "sh04/04.html#aufgabe-5",
    "title": "4  Blatt 04",
    "section": "Aufgabe 5",
    "text": "Aufgabe 5\n\nInterne vs. externe Fragmentierung:\n\nInterne Fragmentierung entsteht, wenn ein Prozess mehr Speicher zugewiesen bekommt, als er tatsächlich benötigt – z. B. bei festen Block- oder Seitengrößen bleibt ungenutzter Speicher innerhalb des Blocks.\nExterne Fragmentierung tritt auf, wenn der freie Speicher zwar insgesamt groß genug ist, aber in viele kleine, nicht zusammenhängende Stücke aufgeteilt ist, sodass größere Prozesse keinen passenden Platz finden.\n\nLogische vs. physische Adressen:\n\nLogische Adressen (auch virtuelle Adressen) werden vom Prozess verwendet und beginnen meist bei 0 – sie sind unabhängig vom realen Speicherlayout.\nPhysische Adressen geben die tatsächliche Position im Hauptspeicher (RAM) an. Das Betriebssystem bzw. die Hardware (MMU) wandelt logische Adressen zur Laufzeit in physische Adressen um.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Blatt 04</span>"
    ]
  },
  {
    "objectID": "sh04/04.html#aufgabe-6",
    "href": "sh04/04.html#aufgabe-6",
    "title": "4  Blatt 04",
    "section": "Aufgabe 6",
    "text": "Aufgabe 6\nKurze erklärung zur Notation: A:B hiesst, dass Segment der Größe A wurde der Speicherlücke der Größe B zugewiesen. Das ist eindeutig, da die Größen der Segmente und der Lücken jeweils eindeutig sind.\nDann:\n\nFirst fit:\n12:20\n11:18\n3:10\n5:7\nBest fit:\n12:12\n11:15\n3:4\n5:7\nWorst fit\n12:20\n11:18\n3:15\n5:12",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Blatt 04</span>"
    ]
  },
  {
    "objectID": "sh04/04.html#aufgabe-7",
    "href": "sh04/04.html#aufgabe-7",
    "title": "4  Blatt 04",
    "section": "Aufgabe 7",
    "text": "Aufgabe 7\nDa die Seitengröße 1 KB = 1024 Bytes = 2¹⁰ beträgt, entsprechen die unteren 10 Bit des virtuellen Adresse die Offset, die restlichen höheren Bits geben die Seitennummer an.\n\nBerechnung der Seitennummern und Offsets:\n\n\n\nAdresse\nSeitennummer\nOffset\n\n\n\n\n2456\n2\n408\n\n\n16382\n15\n1022\n\n\n30000\n29\n304\n\n\n4385\n4\n289\n\n\n\n\n\nC-Code:\n// V - virtuelle Addresse, gegeben\nint p = V &gt;&gt; 10;        // Seitennummer\nint offset = V & 0x3FF; // Offset (2^10 - 1 = 1023)\nDurch die Verwendung von Bitoperationen ist die Berechnung effizient, da die Seitengröße eine Zweierpotenz ist.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Blatt 04</span>"
    ]
  }
]